# ML_NLP_MLOPS
End to end Project - Machine Learning + NLP + MLOPS + Deployment

---
# MLOPS
---
## Flask Framework 

- web server crafted with Python Programming Language.


---

# Deep Learning -

![image](https://github.com/user-attachments/assets/01ced625-b755-417f-8b3e-97467e8b1852)

- Pereptron - single layer neural network - used in solving binary classifiers.
- single layer neural netwok has - 1 hidden layer that is only one neuron.
- when inputs are connected to the hidden layers we, initialize the weights.- random
- hidden layer has z-score = summation of inputs multiplied by the weights wixi +b
- total = step 1 - zscore, step 2 - take activation function and that to z score.
- so the value is now between 0 and 1.
- Perceptron is linear classifier , it separtes the points.- BC
- Finds best fit line to solve classification problem.
- 

#### why we need multi layer neural network ?

![image](https://github.com/user-attachments/assets/55019683-ac56-4507-8b3e-426ed0e13d88)

- perceptron wont be able to solve such complex problems.
- which are not linearly separable.

#### Multi-layer NN Model -
- Forward Propogation
- backward propogation
- Loss functions
- Optimizers
- Activation Functions
- how initial weights are initiazed ?
- loss function vs cost function
- loss function is only calculated for one point/ neuron/ input value
- cost function is calculated over multple points, its summation.
- we updated the error only at once, by combining all error together.
- loss functions for regrssion and classification are different.
- goal is to reduce loss functions.


#### weight updation formuala in backward propogation -
- newW = oldW - (Learning rate * derivative of loss wrt weights)
- the graph of loss vs weights tells us about local minimas / global minima.

![image](https://github.com/user-attachments/assets/57278655-0483-43d6-948d-508dda5b61ad)

- 











